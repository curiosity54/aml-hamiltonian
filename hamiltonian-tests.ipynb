{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import json\n",
    "from equistore import Labels, TensorBlock, TensorMap\n",
    "from utils.builder import TensorBuilder\n",
    "import ase.io\n",
    "from itertools import product\n",
    "from utils.clebsh_gordan import ClebschGordanReal\n",
    "from utils.hamiltonians import fix_pyscf_l1, dense_to_blocks, blocks_to_dense, couple_blocks, decouple_blocks\n",
    "import matplotlib.pyplot as plt\n",
    "from utils.librascal import  RascalSphericalExpansion, RascalPairExpansion\n",
    "from utils.hamiltonians import *\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "water_frames = ase.io.read(\"data/hamiltonian/water-hamiltonian/water_coords_1000.xyz\",\":10\")\n",
    "for f in water_frames:\n",
    "    f.cell = [100,100,100]\n",
    "    f.positions += 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jorbs = json.load(open('data/hamiltonian/water-hamiltonian/orbs_def2_water.json', \"r\"))\n",
    "orbs = {}\n",
    "zdic = {\"O\" : 8, \"H\":1}\n",
    "for k in jorbs:\n",
    "    orbs[zdic[k]] = jorbs[k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ethanol_frames= ase.io.read(\"data/hamiltonian/ethanol-hamiltonian/ethanol_4500.xyz\",\":10\")\n",
    "for f in ethanol_frames:\n",
    "    f.cell = [100,100,100]\n",
    "    f.positions += 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cg = ClebschGordanReal(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rascal_hypers = {\n",
    "    \"interaction_cutoff\": 3.5,\n",
    "    \"cutoff_smooth_width\": 0.5,\n",
    "    \"max_radial\": 3,\n",
    "    \"max_angular\": 2,\n",
    "    \"gaussian_sigma_type\": \"Constant\",\n",
    "    \"compute_gradients\":  False,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frames= [ethanol_frames[0],water_frames[0]]#ethanol_frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spex = RascalSphericalExpansion(rascal_hypers)\n",
    "rhoi = spex.compute(frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rhoi.block(0).components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lm_slice(hypers):\n",
    "    lm_slices = []\n",
    "    start = 0\n",
    "    for l in range(hypers[\"max_angular\"] + 1):\n",
    "        stop = start + 2 * l + 1\n",
    "        lm_slices.append(slice(start, stop))\n",
    "        start = stop\n",
    "    return lm_slices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rascal.representations import SphericalExpansion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hypers=rascal_hypers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# $|\\overline{\\rho^{\\otimes 0}_{ij}; \\lambda \\mu}>$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rho0ij_builder(hypers, frames):\n",
    "    if hypers[\"compute_gradients\"]:\n",
    "        raise Exception(\"Pair expansion with gradient is not implemented\")\n",
    "    len_frames=[len(f) for f in frames]\n",
    "    max_atoms = max(len_frames)\n",
    "    actual_global_species = list(\n",
    "    map(int, np.unique(np.concatenate([f.numbers for f in frames]))))\n",
    "    calculator = SphericalExpansion(**hypers)\n",
    "    manager = calculator.transform(frames)\n",
    "    info = manager.get_representation_info()\n",
    "    global_species = list(range(max_atoms))\n",
    "    \n",
    "    hypers_ij= copy.deepcopy(hypers)\n",
    "    hypers_ij[\"global_species\"] = global_species\n",
    "    hypers_ij[\"expansion_by_species_method\"] = \"user defined\"\n",
    "    lm_slices = get_lm_slice(hypers)\n",
    "\n",
    "    ijframes = []\n",
    "    for f in frames:\n",
    "        ijf = f.copy()\n",
    "        ijf.numbers = global_species[:len(f)]\n",
    "        ijframes.append(ijf)\n",
    "\n",
    "    calculator = SphericalExpansion(**hypers_ij)\n",
    "    gij_expansion=[]\n",
    "    for ijf in ijframes:\n",
    "        gij_expansion.append(calculator.transform(ijf).get_features(calculator).reshape(len(ijf), max_atoms, hypers_ij[\"max_radial\"], -1))\n",
    "#     gij_expansion=calculator.transform(ijframes).get_features(calculator).reshape(len(ijframes), max_atoms, max_atoms, hypers_ij[\"max_radial\"], -1) #TODO: change for differet len\n",
    "#     print(gij_expansion.shape)\n",
    "    \n",
    "    feat_builder= TensorBuilder([\"block_type\", \"L\", \"nu\", \"sigma\",  \"species_i\", \"species_j\"], [\"structure\", \"center_i\", \"center_j\"], [[\"mu\"]], [\"n\"])\n",
    "\n",
    "    pair_loc=[]\n",
    "    lmax = hypers[\"max_angular\"]\n",
    "    for sp_i in actual_global_species:\n",
    "        for sp_j in actual_global_species:\n",
    "            center_species_mask = np.where(info[:, 2] == sp_i)[0]\n",
    "            neighbor_species_mask = np.where(info[:, 2] == sp_j)[0]\n",
    "            for i, (struct_i, atom_i) in enumerate(info[center_species_mask[:]][...,:-1]):\n",
    "                for j, (struct_j, atom_j) in enumerate(info[neighbor_species_mask[:]][...,:-1]):\n",
    "                    ifr=struct_i\n",
    "\n",
    "                    if not (struct_i==struct_j):\n",
    "                        continue\n",
    "                    if atom_i==atom_j:\n",
    "                        block_type = 0  # diagonal\n",
    "                    elif sp_i==sp_j:\n",
    "                        block_type = 1  # same-species\n",
    "                    elif sp_j > sp_i:\n",
    "                        block_type = 2  # different species\n",
    "                    else:\n",
    "                        continue\n",
    "\n",
    "                    if [struct_i, atom_j, atom_i] not in pair_loc:\n",
    "                        pair_loc.append([struct_i, atom_i, atom_j])\n",
    "                    \n",
    "                    for l in range(lmax+1):\n",
    "#                         print(block_type, ifr, l)\n",
    "                        block_idx=(block_type, l, 0, 1, sp_i, sp_j)\n",
    "                        if block_idx not in feat_builder.blocks:\n",
    "                            TensorBlock = feat_builder.add_block(\n",
    "                                keys=block_idx, \n",
    "                                properties=np.asarray([list(range(hypers[\"max_radial\"]))], dtype=np.int32).T, \n",
    "                                components= [np.asarray([list(range(-l, l+1))], dtype=np.int32 ).T] \n",
    "                            )\n",
    "\n",
    "                            if block_type == 1:\n",
    "                                block_asym = feat_builder.add_block(\n",
    "                                    keys=(-1,)+block_idx[1:], \n",
    "                                    properties=np.asarray([list(range(hypers[\"max_radial\"]))], dtype=np.int32).T,\n",
    "                                    components= [np.asarray([list(range(-l, l+1))], dtype=np.int32 ).T]\n",
    "                                )\n",
    "                            \n",
    "                        else:                        \n",
    "                            TensorBlock = feat_builder.blocks[block_idx]\n",
    "                            if block_type == 1:\n",
    "                                block_asym = feat_builder.blocks[(-1,)+block_idx[1:]]\n",
    "\n",
    "                        block_data =gij_expansion[struct_i][atom_i%len_frames[ifr], atom_j%len_frames[ifr], :, lm_slices[l]].T #TODO: change for not water\n",
    "                        #POSSIBLE replacement:(atom_i-sum(info[:struct_i,:].axis=1))%len(info[np.where(info[:,:,0]==struct_i)])\n",
    "                        if block_type == 1:\n",
    "                            if (atom_i%len_frames[ifr])<=(atom_j%len_frames[ifr]):\n",
    "                                block_data_ji = gij_expansion[struct_i][atom_j%len_frames[ifr], atom_i%len_frames[ifr], :, lm_slices[l]].T                  \n",
    "                                TensorBlock.add_samples(labels=np.asarray([[struct_i, atom_i%len_frames[ifr], atom_j%len_frames[ifr]]], dtype=np.int32), data=(block_data+block_data_ji).reshape((1,-1,block_data.shape[1]))/np.sqrt(2) )\n",
    "                                block_asym.add_samples(labels=np.asarray([[struct_i, atom_i%len_frames[ifr], atom_j%len_frames[ifr]]], dtype=np.int32), data=(block_data-block_data_ji).reshape((1,-1,block_data.shape[1]))/np.sqrt(2) )\n",
    "\n",
    "                        else:\n",
    "#                             print(block_data.shape, [struct_i, atom_i%len_frames[ifr], atom_j%len_frames[ifr]])\n",
    "                            TensorBlock.add_samples(labels=np.asarray([[struct_i, atom_i%len_frames[ifr], atom_j%len_frames[ifr]]], dtype=np.int32), data=block_data.reshape(1, -1, block_data.shape[1]))\n",
    "    #                     \n",
    "    return feat_builder.build()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rho0ij=rho0ij_builder(hypers, frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rho0ij.keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rho0ij.block(block_type=2, L=1, nu=0, sigma=1, species_i=8, species_j=1).values\n",
    "\n",
    "#this shouldnt work because we ordered the species in increasing atomic number "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some tests you can do-\n",
    "- for even L's block_type -1 should be zero \n",
    "- for odd L's block_type 1 should be zero \n",
    "- block_type=0 - all values should be the same\n",
    "- block_type=2, interchanging center and neighbor species should give equivalent results (may not be allowed now since we ordered the species)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# $|\\overline{\\rho^{\\otimes 1}_{i};  \\lambda \\mu}>$ from acdc.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_species = sorted(set(rhoi.keys['center_species']))\n",
    "# total_species = list(np.sort(np.asarray(total_species)))\n",
    "lmax=rascal_hypers[\"max_angular\"]\n",
    "nmax=rascal_hypers[\"max_radial\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "blocks = []\n",
    "for l in range(lmax+1):\n",
    "    for sp_i in total_species:\n",
    "        for sp_k in total_species:\n",
    "            n_selected = nmax#len(np.where(opt_eva[l] > sel_thresh)[0])    \n",
    "            de_block = rhoi.block(center_species = sp_i, neighbor_species=sp_k, spherical_harmonics_l = l)\n",
    "            block = TensorBlock(\n",
    "                values = de_block.values,\n",
    "                samples = de_block.samples,\n",
    "                components = [Labels([\"m\"],np.asarray(range(-l,l+1), dtype=np.int32).reshape(-1,1))],\n",
    "                properties = Labels([\"n\"], np.asarray([[n] for n in range(nmax)], dtype=np.int32))\n",
    "            )\n",
    "            \n",
    "            blocks.append( block )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "block.components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acdc_nu1 = TensorMap(\n",
    "    keys = Labels(names=[\"L\", \"nu\", \"sigma\",\"species_i\", \"neighbor_species\"], \n",
    "                        values=np.asarray([[ l, 1, 1, sp_i, sp_k] for l in range(rascal_hypers[\"max_angular\"]+1) \n",
    "                                                        for sp_i in total_species\n",
    "                                                        for sp_k in total_species], dtype=np.int32)\n",
    "                                     ), \n",
    "                      blocks = blocks\n",
    "                     )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# $|\\overline{\\rho^{\\otimes \\nu}_{ij}; \\lambda \\mu}>$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Basically we should build a function that takes a tensor product of $|\\overline{\\rho^0_{ij}}>$ with any $|\\overline{\\rho_i^{nu}}>$, because we can write\n",
    "\n",
    "$$|\\overline{\\rho^\\nu_{ij}; \\lambda \\mu}>  = \\sum_{m h} |\\overline{\\rho^0_{ij}; l m}> |\\overline{\\rho^\\nu_{i}; k h}> <lm; kh|\\lambda \\mu>$$\n",
    "\n",
    "Here we attempt to do this for $\\nu=1$. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nu_ij=rho0ij.keys[\"nu\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rho1 = acdc_nu1.keys_to_properties(\"neighbor_species\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tensor_g_rho_nu(rho0ij, rhoinu, hypers, cg, property_names=None):\n",
    "    \"\"\" rho_ij^{nu+1} = <q|rho_i^{nu+1}; kh> <n| rho_ij^{0}; lm> cg \n",
    "    feature_names is a tuple of the form <n_rho0ij, l_rho0ij, n's in rhoi, k|\n",
    "    Make sure you have transferred the species label to the feature (sparse_to_properties)\n",
    "    \"\"\"\n",
    "    nu_ij=rho0ij.keys[\"nu\"][0]\n",
    "    \n",
    "    # rhoinu = acdc_nu1; \n",
    "    property_names=None\n",
    "    nu_ij=rho0ij.keys[\"nu\"][0] #should be 0\n",
    "    nu_rho= rhoinu.keys[\"nu\"][0]\n",
    "    NU = nu_rho+nu_ij\n",
    "\n",
    "    lmax= hypers[\"max_angular\"]\n",
    "\n",
    "    if cg is None:\n",
    "        cg = ClebschGordanReal(lmax)\n",
    "\n",
    "    sparse_labels=copy.deepcopy(rho0ij.keys)\n",
    "    sparse_labels[\"nu\"] = NU\n",
    "\n",
    "    new_sparse_labels = []\n",
    "    for i in sparse_labels:\n",
    "        new_sparse_labels.append(tuple(i))\n",
    "        i[3]*=-1\n",
    "        if i not in new_sparse_labels:\n",
    "            new_sparse_labels.append(tuple(i))\n",
    "\n",
    "    X_blocks = {new_sparse_labels[i]:[] for i in range(len(new_sparse_labels))}\n",
    "    X_idx = {new_sparse_labels[i]:[] for i in range(len(new_sparse_labels))}\n",
    "    X_samples= {new_sparse_labels[i]:[] for i in range(len(new_sparse_labels))}\n",
    "\n",
    "\n",
    "    if property_names is None:\n",
    "        property_names = (\n",
    "            tuple(n + \"_a\" for n in rho0ij.block(0).properties.names)\n",
    "            + (\"l_\" + str(NU),)\n",
    "            + (\"q_\" + str(NU),) #for n in rhoinu.block(0).features.names)\n",
    "            + (\"k_\" + str(NU),)\n",
    "            )\n",
    "\n",
    "    for index_a, block_a in rho0ij:\n",
    "        block_type = index_a[\"block_type\"]\n",
    "        lam_a = index_a[\"L\"]\n",
    "        sigma_a = index_a[\"sigma\"]\n",
    "        sp_i, sp_j = index_a[\"species_i\"], index_a[\"species_j\"]\n",
    "        for index_b, block_b in rhoinu:\n",
    "            lam_b = index_b[\"L\"]\n",
    "            sigma_b = index_b[\"sigma\"]\n",
    "            rho_sp_i= index_b[\"species_i\"]\n",
    "            if not(sp_i== rho_sp_i):\n",
    "                continue\n",
    "            for L in range(np.abs(lam_a - lam_b),  min(lam_a + lam_b, lmax)+1):\n",
    "                S = sigma_a * sigma_b * (-1) ** (lam_a + lam_b + L)\n",
    "                block_idx=(block_type, L, NU, S, sp_i, sp_j)\n",
    "                sel_feats=[]\n",
    "                for n_a in range(len(block_a.properties)):\n",
    "                    f_a = tuple(block_a.properties[n_a]) #values of n_a'th feature in block_a.features\n",
    "                    for n_b in range(len(block_b.properties)):\n",
    "                        f_b = tuple(block_b.properties[n_b]) #values of n_b'th feature in block_b.features\n",
    "                        IDX = f_a  + (lam_a,)+ (''.join(map(str, f_b)),) + (lam_b,)\n",
    "                        #IDX = f_a  + (lam_a,)+f_b + (lam_b,)\n",
    "                        sel_feats.append([n_a, n_b])\n",
    "                        X_idx[block_idx].append(IDX)\n",
    "\n",
    "                sel_feats = np.asarray(sel_feats, dtype=int)\n",
    "                if len(sel_feats) == 0:\n",
    "                    print(IDX, L, \"len_feats 0\")\n",
    "                    continue\n",
    "\n",
    "    #             #REMEMBER- values.shape = (nstruct*nat fitting the block criteria, 2*l+1, featsize)\n",
    "                if block_type==0:\n",
    "                    if not(sp_i== rho_sp_i):\n",
    "                        continue\n",
    "                    one_shot_blocks = cg.combine_einsum(\n",
    "                     block_a.values[:, :, sel_feats[:, 0]],  #sel_feats[:,0]= n_a\n",
    "                     block_b.values[:, :, sel_feats[:, 1]],  #sel_feats[:,1]= n_b*nspecies\n",
    "                    L,\n",
    "                    combination_string=\"iq,iq->iq\",\n",
    "                ) \n",
    "\n",
    "                    samples = block_a.samples\n",
    "                    \n",
    "                else:\n",
    "                    xx=[]\n",
    "                    yy=[]\n",
    "                    for samplea in block_a.samples:\n",
    "                        centeri = samplea['center_i']\n",
    "                        centerj = samplea['center_j']\n",
    "                        stra = samplea['structure']\n",
    "                        idxb= block_b.samples[np.where(block_b.samples['center']==centeri)]\n",
    "                        samples_idxb=block_b.samples[np.where(np.in1d(block_b.samples,idxb))[0]]\n",
    "                        xx.append(samples_idxb[np.where(samples_idxb['structure']==stra)[0]])\n",
    "                        if (block_type==1 or block_type==-1):\n",
    "                            idxbj= block_b.samples[np.where(block_b.samples['center']==centerj)]\n",
    "                            samples_idxbj=block_b.samples[np.where(np.in1d(block_b.samples,idxbj))[0]]\n",
    "                            yy.append(samples_idxbj[np.where(samples_idxbj['structure']==stra)[0]])\n",
    "                    #     yy.append()\n",
    "                    ixx=[np.where(i==block_b.samples)[0][0] for i in xx]\n",
    "                    iyy=[np.where(i==block_b.samples)[0][0] for i in yy]\n",
    "                    rhoinuvalues = block_b.values[ixx]\n",
    "                    rhojnuvalues = block_b.values[iyy]\n",
    "\n",
    "                    if (block_type==1 or block_type==-1): \n",
    "                        if not(sp_i== rho_sp_i):\n",
    "                            continue\n",
    "                        one_shot_blocks_ij = cg.combine_einsum(\n",
    "                         block_a.values[:, :, sel_feats[:, 0]], \n",
    "                         rhoinuvalues[:, :, sel_feats[:, 1]],\n",
    "                        L,\n",
    "                        combination_string=\"iq,iq->iq\",\n",
    "                    )\n",
    "\n",
    "                        one_shot_blocks_ji = cg.combine_einsum(\n",
    "                         block_a.values[:, :, sel_feats[:, 0]], \n",
    "                         rhojnuvalues[:, :, sel_feats[:, 1]],\n",
    "                        L,\n",
    "                        combination_string=\"iq,iq->iq\",\n",
    "                    )\n",
    "                        samples = block_a.samples\n",
    "                        \n",
    "                        if block_type==1:\n",
    "                            one_shot_blocks = (one_shot_blocks_ij+one_shot_blocks_ji)/np.sqrt(2)\n",
    "                        elif block_type==-1:\n",
    "                            one_shot_blocks = (one_shot_blocks_ij-one_shot_blocks_ji)/np.sqrt(2)\n",
    "\n",
    "\n",
    "#                    elif block_type==-1:\n",
    "#                        if not(sp_i== rho_sp_i):\n",
    "#                            continue\n",
    "#                        one_shot_blocks_ij = cg.combine_einsum(\n",
    "#                         block_a.values[:, :, sel_feats[:, 0]], \n",
    "#                         rhoinuvalues[:, :, sel_feats[:, 1]],\n",
    "#                        L,\n",
    "#                        combination_string=\"iq,iq->iq\",\n",
    "#                    )\n",
    "#\n",
    "#                        one_shot_blocks_ji = cg.combine_einsum(\n",
    "#                         block_a.values[:, :, sel_feats[:, 0]], \n",
    "#                         rhojnuvalues[:, :, sel_feats[:, 1]],\n",
    "#                        L,\n",
    "#                        combination_string=\"iq,iq->iq\",\n",
    "#                    )\n",
    "#                        samples = block_a.samples\n",
    "#                        one_shot_blocks = (one_shot_blocks_ij-one_shot_blocks_ji)/np.sqrt(2)\n",
    "\n",
    "                    elif block_type==2:\n",
    "                        #TODO: recheck this \n",
    "        #                     if sp_i<rho_sp_i:\n",
    "        #                         continue\n",
    "                        if not(sp_i== rho_sp_i):\n",
    "                            continue\n",
    "                        \n",
    "                        #print(sp_i, rho_sp_i, sp_j, block_a.values.shape, block_b.values.shape)\n",
    "                        one_shot_blocks = cg.combine_einsum(\n",
    "                         block_a.values[:, :, sel_feats[:, 0]], \n",
    "                         rhoinuvalues[:, :, sel_feats[:, 1]],\n",
    "                        L,\n",
    "                        combination_string=\"iq,iq->iq\",\n",
    "                    )\n",
    "                        samples = block_a.samples\n",
    "\n",
    "                for Q in range(len(sel_feats)):\n",
    "                    (n_a, n_b) = sel_feats[Q]\n",
    "                    n=block_b.properties[n_b]\n",
    "                    IDX = (n_a,)  + (lam_a,)+(''.join(map(str, n)),) + (lam_b,)\n",
    "                    newblock = one_shot_blocks[:, :, Q]\n",
    "   \n",
    "                    X_blocks[block_idx].append(newblock)\n",
    "                    X_samples[block_idx].append(samples)\n",
    "    nonzero_idx = []\n",
    "\n",
    "    nonzero_blocks = []\n",
    "    for block_idx in X_blocks:\n",
    "        block_type, L, NU, S, sp_i, sp_j = block_idx\n",
    "        # create blocks\n",
    "        if len(X_blocks[block_idx]) == 0:\n",
    "            #print(block_idx, \"skipped\")\n",
    "            continue  # skips empty blocks\n",
    "\n",
    "        nonzero_idx.append(block_idx)\n",
    "        block_data = np.moveaxis(np.asarray(X_blocks[block_idx]), 0, -1) \n",
    "        block_samples = X_samples[block_idx][0]\n",
    "        newblock = TensorBlock(\n",
    "            values=block_data,\n",
    "            samples=block_samples,\n",
    "            components=[Labels(\n",
    "                [\"mu\"], np.asarray(range(-L, L + 1), dtype=np.int32).reshape(-1, 1)\n",
    "            )],\n",
    "            properties=Labels(property_names, np.asarray(X_idx[block_idx], dtype=np.int32)),\n",
    "        )\n",
    "\n",
    "        nonzero_blocks.append(newblock)\n",
    "        print(block_idx, 'done')\n",
    "\n",
    "    X = TensorMap(\n",
    "        Labels(rho0ij.keys.names, np.asarray(nonzero_idx, dtype=np.int32)), nonzero_blocks\n",
    "    )\n",
    "\n",
    "\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rho1ij=tensor_g_rho_nu(rho0ij, acdc_nu1, rascal_hypers, cg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rho1ij.keys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TODO**: \n",
    "   - Check if the feature we get here is the same as in ncenter-reps\n",
    "   - Fix the the offd_m/offd_p computation - we are repeating calculations of block_ij, block_ji - we should reuse this (blocks_asym commented out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ACDC for nu=2 and $|\\overline{\\rho^{\\otimes 2}_{ij}; \\lambda \\mu}>$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def acdc_rho_nu(rhoinu1, rhoinu2, hypers, cg, property_names=None):\n",
    "    \"\"\" rho_ij^{nu+1} = <q|rho_i^{nu+1}; kh> <n| rho_ij^{0}; lm> cg \n",
    "    feature_names is a tuple of the form <n_rho0ij, l_rho0ij, n's in rhoi, k|\n",
    "    Make sure you have transferred the species label to the feature (sparse_to_features)\n",
    "    \"\"\"\n",
    "    nu_1=rhoinu1.keys[\"nu\"][0]\n",
    "    nu_2=rhoinu2.keys[\"nu\"][0]\n",
    "    \n",
    "    property_names=None\n",
    "\n",
    "    NU = nu_1+nu_2\n",
    "\n",
    "    lmax= hypers[\"max_angular\"]\n",
    "\n",
    "    if cg is None:\n",
    "        cg = ClebschGordanReal(lmax)\n",
    "\n",
    "    sparse_labels=copy.deepcopy(rhoinu1.keys)\n",
    "    sparse_labels[\"nu\"] = NU\n",
    "\n",
    "    new_sparse_labels = []\n",
    "    for i in sparse_labels:\n",
    "        new_sparse_labels.append(tuple(i))\n",
    "        i[2]*=-1\n",
    "        if i not in new_sparse_labels:\n",
    "            new_sparse_labels.append(tuple(i))\n",
    "\n",
    "    X_blocks = {new_sparse_labels[i]:[] for i in range(len(new_sparse_labels))}\n",
    "    X_idx = {new_sparse_labels[i]:[] for i in range(len(new_sparse_labels))}\n",
    "    X_samples= {new_sparse_labels[i]:[] for i in range(len(new_sparse_labels))}\n",
    "\n",
    "\n",
    "    if property_names is None:\n",
    "        property_names = (\n",
    "            tuple(n + \"_1\" for n in rhoinu1.block(0).properties.names)\n",
    "            + (\"l_\" + str(NU),)\n",
    "            + tuple(n + \"_2\" for n in rhoinu2.block(0).properties.names)\n",
    "            + (\"k_\" + str(NU),)\n",
    "        )\n",
    "\n",
    "    for index_a, block_a in rhoinu1:\n",
    "        lam_a = index_a[\"L\"]\n",
    "        sigma_a = index_a[\"sigma\"]\n",
    "        rho_sp_i = index_a[\"species_i\"]\n",
    "        for index_b, block_b in rhoinu2:\n",
    "            lam_b = index_b[\"L\"]\n",
    "            sigma_b = index_b[\"sigma\"]\n",
    "            rho_sp_i2= index_b[\"species_i\"]\n",
    "            if not(rho_sp_i== rho_sp_i2):\n",
    "                continue\n",
    "            for L in range(np.abs(lam_a - lam_b),  min(lam_a + lam_b, lmax)+1):\n",
    "                S = sigma_a * sigma_b * (-1) ** (lam_a + lam_b + L)\n",
    "                block_idx=(L, NU, S, rho_sp_i)\n",
    "                sel_feats=[]\n",
    "                for n_a in range(len(block_a.properties)):\n",
    "                    f_a = tuple(block_a.properties[n_a]) #values of n_a'th feature in block_a.features\n",
    "                    for n_b in range(len(block_b.properties)):\n",
    "                        f_b = tuple(block_b.properties[n_b]) #values of n_b'th feature in block_b.features\n",
    "                        IDX = f_a  + (lam_a,)+f_b + (lam_b,)\n",
    "                        sel_feats.append([n_a, n_b])\n",
    "                        X_idx[block_idx].append(IDX)\n",
    "\n",
    "                sel_feats = np.asarray(sel_feats, dtype=int)\n",
    "                if len(sel_feats) == 0:\n",
    "                    print(IDX, L, \"len_feats 0\")\n",
    "                    continue\n",
    "\n",
    "    #             #REMEMBER- values.shape = (nstruct*nat fitting the block criteria, 2*l+1, featsize)\n",
    "            \n",
    "    \n",
    "                one_shot_blocks = cg.combine_einsum(\n",
    "                 block_a.values[:, :, sel_feats[:, 0]],  #sel_feats[:,0]= n_a\n",
    "                 block_b.values[:, :, sel_feats[:, 1]],  #sel_feats[:,1]= n_b*nspecies\n",
    "                L,\n",
    "                combination_string=\"iq,iq->iq\",\n",
    "            ) \n",
    "\n",
    "                samples = block_a.samples\n",
    "\n",
    "\n",
    "                for Q in range(len(sel_feats)):\n",
    "                    (n_a, n_b) = sel_feats[Q]\n",
    "                    n = block_b.properties[n_b]  #how to generalize this for nu\n",
    "                    \n",
    "                    IDX = (n_a,)  + (lam_a,)+(n,) + (lam_b,)\n",
    "                    newblock = one_shot_blocks[:, :, Q]\n",
    "   \n",
    "                    X_blocks[block_idx].append(newblock)\n",
    "                    X_samples[block_idx].append(samples)\n",
    "    nonzero_idx = []\n",
    "\n",
    "    nonzero_blocks = []\n",
    "    for block_idx in X_blocks:\n",
    "        L, NU, S, rho_sp_i = block_idx\n",
    "        # create blocks\n",
    "        if len(X_blocks[block_idx]) == 0:\n",
    "#             print(block_idx, \"skipped\")\n",
    "            continue  # skips empty blocks\n",
    "\n",
    "        nonzero_idx.append(block_idx)\n",
    "        block_data = np.moveaxis(np.asarray(X_blocks[block_idx]), 0, -1) \n",
    "        block_samples = X_samples[block_idx][0]\n",
    "    \n",
    "        newblock = TensorBlock(\n",
    "            values=block_data,\n",
    "            samples=block_samples,\n",
    "            components=[Labels(\n",
    "                [\"mu\"], np.asarray(range(-L, L + 1), dtype=np.int32).reshape(-1, 1)\n",
    "            )],\n",
    "            properties=Labels(property_names, np.asarray(X_idx[block_idx], dtype=np.int32)),\n",
    "        )\n",
    "\n",
    "        nonzero_blocks.append(newblock)\n",
    "        print(block_idx, 'done')\n",
    "\n",
    "    X = TensorMap(\n",
    "        Labels(rhoinu1.keys.names, np.asarray(nonzero_idx, dtype=np.int32)), nonzero_blocks\n",
    "    )\n",
    "\n",
    "\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acdc_nu2 = acdc_rho_nu(acdc_nu1, acdc_nu1, hypers, cg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _matrix_sqrt(MMT):\n",
    "    eva, eve = np.linalg.eigh(MMT)\n",
    "    return (eve * np.sqrt(eva)) @ eve.T\n",
    "\n",
    "def compress_features(x, w=None, threshold=None):\n",
    "    new_blocks = []\n",
    "    new_idxs = []\n",
    "    new_A = []\n",
    "    for index, block in x:\n",
    "        nfeats = block.values.shape[-1]\n",
    "        L = index['L']\n",
    "\n",
    "        # makes a copy of the features\n",
    "        X = block.values.reshape(-1, nfeats).copy()\n",
    "        selection = []\n",
    "        while len(selection) < nfeats:\n",
    "            norm = (X**2).sum(axis=0)\n",
    "            sel_idx = norm.argmax()\n",
    "            \n",
    "            if norm[sel_idx] / (2 * L + 1) / X.shape[0] < threshold:\n",
    "                break\n",
    "            sel_x = X[:, sel_idx] / np.sqrt(norm[sel_idx])\n",
    "            selection.append(sel_idx)\n",
    "            \n",
    "            # orthogonalize\n",
    "            X -= sel_x.reshape(-1, 1) @ (sel_x @ X).reshape(1, -1)\n",
    "        selection.sort()\n",
    "        nsel = len(selection)\n",
    "        if nsel == 0:\n",
    "            continue\n",
    "        new_idxs.append(tuple(index))\n",
    "        \n",
    "        Xt = block.values.reshape(-1, nfeats)[:, selection].copy()\n",
    "        if w is not None:\n",
    "            for i, s in enumerate(selection):\n",
    "                Xt[:, i] /= w.block(index).values[0, 0, s]\n",
    "        \n",
    "        W = np.linalg.pinv(Xt) @ block.values.reshape(-1, nfeats)\n",
    "        WW = W @ W.T\n",
    "        A = _matrix_sqrt(WW)\n",
    "        Xt = Xt @ A\n",
    "        new_blocks.append(\n",
    "            TensorBlock(\n",
    "                values=Xt.reshape(block.values.shape[:2] + (-1,)),\n",
    "                samples=block.samples,\n",
    "                components=block.components,\n",
    "                properties=block.properties[selection],\n",
    "            )\n",
    "        )\n",
    "        new_A.append(\n",
    "            TensorBlock(\n",
    "                values=A.T.reshape(1, nsel, nsel),\n",
    "                components=[Labels(\n",
    "                    [\"q_comp\"], np.arange(nsel, dtype=np.int32).reshape(-1, 1)\n",
    "                )],\n",
    "                samples=Labels([\"dummy\"], np.zeros(shape=(1, 1), dtype=np.int32)),\n",
    "                properties=block.properties[selection],\n",
    "            )\n",
    "        )\n",
    "        new_sparse = Labels(x.keys.names, np.asarray(new_idxs, dtype=np.int32))\n",
    "        \n",
    "    return TensorMap(new_sparse, new_blocks), TensorMap(new_sparse, new_A)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comp_feats_nu2, _ = compress_features(acdc_nu2, threshold=1e-12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "rho2ij=tensor_g_rho_nu(rho0ij, comp_feats_nu2, rascal_hypers, cg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feats = rho2ij"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e5b9818494c5e2e4b1f356a8c3298778da7fbcf7ee16e565b1a5192ca7e31aaa"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.11"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
