{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import json\n",
    "from aml_storage import Labels, Block, Descriptor\n",
    "from utils.builder import DescriptorBuilder\n",
    "import ase.io\n",
    "from itertools import product\n",
    "from utils.clebsh_gordan import ClebschGordanReal\n",
    "from utils.hamiltonians import fix_pyscf_l1, dense_to_blocks, blocks_to_dense, couple_blocks, decouple_blocks\n",
    "import matplotlib.pyplot as plt\n",
    "from utils.librascal import  RascalSphericalExpansion, RascalPairExpansion\n",
    "from utils.hamiltonians import *\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "frames = ase.io.read(\"data/water-hamiltonian/water_coords_1000.xyz\",\":1000\")\n",
    "for f in frames:\n",
    "    f.cell = [100,100,100]\n",
    "    f.positions += 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "jorbs = json.load(open('data/water-hamiltonian/orbs_def2_water.json', \"r\"))\n",
    "orbs = {}\n",
    "zdic = {\"O\" : 8, \"H\":1}\n",
    "for k in jorbs:\n",
    "    orbs[zdic[k]] = jorbs[k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "cg = ClebschGordanReal(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "rascal_hypers = {\n",
    "    \"interaction_cutoff\": 3.5,\n",
    "    \"cutoff_smooth_width\": 0.5,\n",
    "    \"max_radial\": 3,\n",
    "    \"max_angular\": 2,\n",
    "    \"gaussian_sigma_type\": \"Constant\",\n",
    "    \"compute_gradients\":  False,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "spex = RascalSphericalExpansion(rascal_hypers)\n",
    "rhoi = spex.compute(frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lm_slice(hypers):\n",
    "    lm_slices = []\n",
    "    start = 0\n",
    "    for l in range(hypers[\"max_angular\"] + 1):\n",
    "        stop = start + 2 * l + 1\n",
    "        lm_slices.append(slice(start, stop))\n",
    "        start = stop\n",
    "    return lm_slices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rascal.representations import SphericalExpansion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "pairs = RascalPairExpansion(rascal_hypers)\n",
    "gij = pairs.compute(frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_rho0ij(hypers, frames):\n",
    "    lmax= hypers[\"max_angular\"]\n",
    "    pairs = RascalPairExpansion(hypers)\n",
    "    gij = pairs.compute(frames)\n",
    "    new_sparse = Labels(\n",
    "    names=[\"sigma\", \"L\", \"nu\"],\n",
    "    values=np.array(\n",
    "        [\n",
    "            [1, l, 0]\n",
    "            for l in range(hypers[\"max_angular\"] + 1)                    \n",
    "        ],\n",
    "        dtype=np.int32,\n",
    "            ),\n",
    "        )\n",
    "    blocks=[]\n",
    "    for idx, block in gij:\n",
    "        blocks.append(block.copy())\n",
    "    return Descriptor(new_sparse, blocks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "hypers=rascal_hypers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "old_rho0ij=compute_rho0ij(hypers, frames)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# $|\\overline{\\rho^{\\otimes 0}_{ij}; \\lambda \\mu}>$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# works for just water"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_rho0ij_builder(hypers, frames):\n",
    "    if hypers[\"compute_gradients\"]:\n",
    "        raise Exception(\"Pair expansion with gradient is not implemented\")\n",
    "\n",
    "    max_atoms = max([len(f) for f in frames])\n",
    "    actual_global_species = list(\n",
    "    map(int, np.unique(np.concatenate([f.numbers for f in frames]))))\n",
    "    calculator = SphericalExpansion(**hypers)\n",
    "    manager = calculator.transform(frames)\n",
    "    info = manager.get_representation_info()\n",
    "    global_species = list(range(max_atoms))\n",
    "    \n",
    "    hypers_ij= copy.deepcopy(hypers)\n",
    "    hypers_ij[\"global_species\"] = global_species\n",
    "    hypers_ij[\"expansion_by_species_method\"] = \"user defined\"\n",
    "    lm_slices = get_lm_slice(hypers)\n",
    "\n",
    "    ijframes = []\n",
    "    for f in frames:\n",
    "        ijf = f.copy()\n",
    "        ijf.numbers = global_species[:len(f)]\n",
    "        ijframes.append(ijf)\n",
    "\n",
    "    calculator = SphericalExpansion(**hypers_ij)\n",
    "    gij_expansion=calculator.transform(ijframes).get_features(calculator).reshape(len(ijframes), len(ijf), max_atoms, hypers_ij[\"max_radial\"], -1) #TODO: change for differet len\n",
    "#     print(gij_expansion.shape)\n",
    "    \n",
    "    feat_builder= DescriptorBuilder([\"block_type\", \"L\", \"nu\", \"sigma\",  \"species_i\", \"species_j\"], [\"structure\", \"center_i\", \"center_j\"], [\"mu\"], [\"n\"])\n",
    "\n",
    "    pair_loc=[]\n",
    "    lmax = hypers[\"max_angular\"]\n",
    "    for sp_i in actual_global_species:\n",
    "        for sp_j in actual_global_species:\n",
    "            center_species_mask = np.where(info[:, 2] == sp_i)[0]\n",
    "            neighbor_species_mask = np.where(info[:, 2] == sp_j)[0]\n",
    "            for i, (struct_i, atom_i) in enumerate(info[center_species_mask[:]][...,:-1]):\n",
    "                for j, (struct_j, atom_j) in enumerate(info[neighbor_species_mask[:]][...,:-1]):\n",
    "                    if not (struct_i==struct_j):\n",
    "                        continue\n",
    "                    if atom_i==atom_j:\n",
    "                            block_type = 0  # diagonal\n",
    "                    elif sp_i==sp_j:\n",
    "                        block_type = 1  # same-species\n",
    "                    elif sp_j > sp_i:\n",
    "                        \n",
    "                        block_type = 2  # different species\n",
    "                    else:\n",
    "                        continue\n",
    "                        \n",
    "                    if [struct_i, atom_j, atom_i] not in pair_loc:\n",
    "                        pair_loc.append([struct_i, atom_i, atom_j])\n",
    "\n",
    "                    for l in range(lmax+1):\n",
    "                        block_idx=(block_type, l, 0, 1, sp_i, sp_j)\n",
    "                        if block_idx not in feat_builder.blocks:\n",
    "                            block = feat_builder.add_block(sparse=block_idx, features=np.asarray([list(range(hypers[\"max_radial\"]))], dtype=np.int32).T, \n",
    "                                components=np.asarray([list(range(-l, l+1))], dtype=np.int32 ).T )  \n",
    "                            \n",
    "                        \n",
    "                            if block_type == 1:\n",
    "                                block_asym = feat_builder.add_block(sparse=(-1,)+block_idx[1:], features=np.asarray([list(range(hypers[\"max_radial\"]))], dtype=np.int32).T,\n",
    "                                components=np.asarray([list(range(-l, l+1))], dtype=np.int32 ).T )                                                    \n",
    "                        else:                        \n",
    "                            block = feat_builder.blocks[block_idx]\n",
    "                            if block_type == 1:\n",
    "                                block_asym = feat_builder.blocks[(-1,)+block_idx[1:]]\n",
    "\n",
    "                        block_data =gij_expansion[struct_i][atom_i%3, atom_j%3, :, lm_slices[l]].T #TODO: change for not water\n",
    "                        #POSSIBLE replacement:(atom_i-sum(info[:struct_i,:].axis=1))%len(info[np.where(info[:,:,0]==struct_i)])\n",
    "                        if block_type == 1:\n",
    "                            if atom_i%3 <=atom_j%3:\n",
    "                                block_data_ji = gij_expansion[struct_i][atom_j%3, atom_i%3, :, lm_slices[l]].T                  \n",
    "                                block.add_samples(labels=np.asarray([[struct_i, atom_i%3, atom_j%3]], dtype=np.int32), data=(block_data+block_data_ji).reshape((1,-1,block_data.shape[1]))/np.sqrt(2) )\n",
    "                                block_asym.add_samples(labels=np.asarray([[struct_i, atom_i%3, atom_j%3]], dtype=np.int32), data=(block_data-block_data_ji).reshape((1,-1,block_data.shape[1]))/np.sqrt(2) )\n",
    "                        else:\n",
    "#                       \n",
    "                            block.add_samples(labels=np.asarray([[struct_i, atom_i%3, atom_j%3]], dtype=np.int32), data=block_data.reshape(1, -1, block_data.shape[1]))\n",
    "    #                     \n",
    "\n",
    "    return feat_builder.build()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "rho0ij=compute_rho0ij_builder(hypers, frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Labels([( 0, 0, 0, 1, 1, 1), ( 0, 1, 0, 1, 1, 1), ( 0, 2, 0, 1, 1, 1),\n",
       "        ( 1, 0, 0, 1, 1, 1), (-1, 0, 0, 1, 1, 1), ( 1, 1, 0, 1, 1, 1),\n",
       "        (-1, 1, 0, 1, 1, 1), ( 1, 2, 0, 1, 1, 1), (-1, 2, 0, 1, 1, 1),\n",
       "        ( 2, 0, 0, 1, 1, 8), ( 2, 1, 0, 1, 1, 8), ( 2, 2, 0, 1, 1, 8),\n",
       "        ( 0, 0, 0, 1, 8, 8), ( 0, 1, 0, 1, 8, 8), ( 0, 2, 0, 1, 8, 8)],\n",
       "       dtype=[('block_type', '<i4'), ('L', '<i4'), ('nu', '<i4'), ('sigma', '<i4'), ('species_i', '<i4'), ('species_j', '<i4')])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rho0ij.sparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rho0ij.block(block_type=2, L=1, nu=0, sigma=1, species_i=8, species_j=1).values\n",
    "\n",
    "#this shouldnt work because we ordered the species in increasing atomic number "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some tests you can do-\n",
    "- for even L's block_type -1 should be zero \n",
    "- for odd L's block_type 1 should be zero \n",
    "- block_type=0 - all values should be the same\n",
    "- block_type=2, interchanging center and neighbor species should give equivalent results (may not be allowed now since we ordered the species)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rho0ij.block(block_type=2, L=0, nu=0, sigma=1, species_i=8, species_j=1).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to verify with the rascal spherical expansion- find indices of the relevant samples\n",
    "idx=[]\n",
    "i=0\n",
    "for (struct, center_i, center_j, species_i, species_j) in old_rho0ij.block(L=0).samples:\n",
    "    \n",
    "    if center_i==center_j: \n",
    "        idx.append(i)\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 0.01039805, -0.00505374,  0.0002431 ]],\n",
       "\n",
       "       [[ 0.01039805, -0.00505374,  0.0002431 ]],\n",
       "\n",
       "       [[ 0.01039805, -0.00505374,  0.0002431 ]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[ 0.01039805, -0.00505374,  0.0002431 ]],\n",
       "\n",
       "       [[ 0.01039805, -0.00505374,  0.0002431 ]],\n",
       "\n",
       "       [[ 0.01039805, -0.00505374,  0.0002431 ]]])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "old_rho0ij.block(L=0).values[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Labels([( 0, 0, 0, 1, 1, 1), ( 0, 1, 0, 1, 1, 1), ( 0, 2, 0, 1, 1, 1),\n",
       "        ( 1, 0, 0, 1, 1, 1), (-1, 0, 0, 1, 1, 1), ( 1, 1, 0, 1, 1, 1),\n",
       "        (-1, 1, 0, 1, 1, 1), ( 1, 2, 0, 1, 1, 1), (-1, 2, 0, 1, 1, 1),\n",
       "        ( 2, 0, 0, 1, 1, 8), ( 2, 1, 0, 1, 1, 8), ( 2, 2, 0, 1, 1, 8),\n",
       "        ( 0, 0, 0, 1, 8, 8), ( 0, 1, 0, 1, 8, 8), ( 0, 2, 0, 1, 8, 8)],\n",
       "       dtype=[('block_type', '<i4'), ('L', '<i4'), ('nu', '<i4'), ('sigma', '<i4'), ('species_i', '<i4'), ('species_j', '<i4')])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rho0ij.sparse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# $|\\overline{\\rho^{\\otimes 1}_{i};  \\lambda \\mu}>$ from acdc.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_species = sorted(set(rhoi.sparse['center_species']))\n",
    "# total_species = list(np.sort(np.asarray(total_species)))\n",
    "lmax=rascal_hypers[\"max_angular\"]\n",
    "nmax=rascal_hypers[\"max_radial\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "blocks = []\n",
    "for l in range(lmax+1):\n",
    "    for sp_i in total_species:\n",
    "        for sp_k in total_species:\n",
    "            n_selected = nmax#len(np.where(opt_eva[l] > sel_thresh)[0])    \n",
    "            de_block = rhoi.block(center_species = sp_i, neighbor_species=sp_k, spherical_harmonics_l = l)\n",
    "            block = Block(\n",
    "                values = de_block.values,\n",
    "                samples = de_block.samples,\n",
    "                components = Labels([\"m\"],np.asarray(range(-l,l+1), dtype=np.int32).reshape(-1,1)),\n",
    "                features = Labels([\"n\"], np.asarray([[n] for n in range(nmax)], dtype=np.int32))\n",
    "            )\n",
    "            \n",
    "            blocks.append( block )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Labels([(-2,), (-1,), ( 0,), ( 1,), ( 2,)], dtype=[('m', '<i4')])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "block.components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "acdc_nu1 = Descriptor(sparse = Labels(names=[\"L\", \"nu\", \"sigma\",\"species_i\", \"neighbor_species\"], \n",
    "                                      values=np.asarray([[ l, 1, 1, sp_i, sp_k] for l in range(rascal_hypers[\"max_angular\"]+1) \n",
    "                                                        for sp_i in total_species\n",
    "                                                        for sp_k in total_species], dtype=np.int32)\n",
    "                                     ), \n",
    "                      blocks = blocks\n",
    "                     )\n",
    "#move neighbor species to features  \n",
    "# acdc_nu1.sparse_to_features('neighbor_species')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# $|\\overline{\\rho^{\\otimes \\nu}_{ij}; \\lambda \\mu}>$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Basically we should build a function that takes a tensor product of $|\\overline{\\rho^0_{ij}}>$ with any $|\\overline{\\rho_i^nu}>$, because we can write\n",
    "\n",
    "$$|\\overline{\\rho^\\nu_{ij}; \\lambda \\mu}>  = \\sum_{m h} |\\overline{\\rho^0_{ij}; l m}> |\\overline{\\rho^\\nu_{i}; k h}> <lm; kh|\\lambda \\mu>$$\n",
    "\n",
    "Here we attempt to do this for $\\nu=1$. \n",
    "\n",
    "\n",
    "**works for **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "nu_ij=rho0ij.sparse[\"nu\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "rho1 = acdc_nu1.sparse_to_features(\"neighbor_species\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tensor_g_rho_nu(rho0ij, rhoinu, hypers, cg, feature_names=None):\n",
    "    \"\"\" rho_ij^{nu+1} = <q|rho_i^{nu+1}; kh> <n| rho_ij^{0}; lm> cg \n",
    "    feature_names is a tuple of the form <n_rho0ij, l_rho0ij, n's in rhoi, k|\n",
    "    Make sure you have transferred the species label to the feature (sparse_to_features)\n",
    "    \"\"\"\n",
    "    nu_ij=rho0ij.sparse[\"nu\"][0]\n",
    "    \n",
    "    # rhoinu = acdc_nu1; \n",
    "    feature_names=None\n",
    "    nu_ij=rho0ij.sparse[\"nu\"][0] #should be 0\n",
    "    nu_rho= rhoinu.sparse[\"nu\"][0]\n",
    "    NU = nu_rho+nu_ij\n",
    "\n",
    "    lmax= hypers[\"max_angular\"]\n",
    "\n",
    "    if cg is None:\n",
    "        cg = ClebschGordanReal(lmax)\n",
    "\n",
    "    sparse_labels=copy.deepcopy(rho0ij.sparse)\n",
    "    sparse_labels[\"nu\"] = NU\n",
    "\n",
    "    new_sparse_labels = []\n",
    "    for i in sparse_labels:\n",
    "        new_sparse_labels.append(tuple(i))\n",
    "        i[3]*=-1\n",
    "        if i not in new_sparse_labels:\n",
    "            new_sparse_labels.append(tuple(i))\n",
    "\n",
    "    X_blocks = {new_sparse_labels[i]:[] for i in range(len(new_sparse_labels))}\n",
    "    X_idx = {new_sparse_labels[i]:[] for i in range(len(new_sparse_labels))}\n",
    "    X_samples= {new_sparse_labels[i]:[] for i in range(len(new_sparse_labels))}\n",
    "\n",
    "\n",
    "    if feature_names is None:\n",
    "        feature_names = (\n",
    "            tuple(n + \"_a\" for n in rho0ij.block(0).features.names)\n",
    "            + (\"l_\" + str(NU),)\n",
    "            + tuple(n + \"_b\" for n in acdc_nu1.block(0).features.names)\n",
    "            + (\"k_\" + str(NU),)\n",
    "        )\n",
    "\n",
    "    for index_a, block_a in rho0ij:\n",
    "        block_type = index_a[\"block_type\"]\n",
    "        lam_a = index_a[\"L\"]\n",
    "        sigma_a = index_a[\"sigma\"]\n",
    "        sp_i, sp_j = index_a[\"species_i\"], index_a[\"species_j\"]\n",
    "        for index_b, block_b in rhoinu:\n",
    "            lam_b = index_b[\"L\"]\n",
    "            sigma_b = index_b[\"sigma\"]\n",
    "            rho_sp_i= index_b[\"species_i\"]\n",
    "            if not(sp_i== rho_sp_i):\n",
    "                continue\n",
    "            for L in range(np.abs(lam_a - lam_b),  min(lam_a + lam_b, lmax)+1):\n",
    "                S = sigma_a * sigma_b * (-1) ** (lam_a + lam_b + L)\n",
    "                block_idx=(block_type, L, NU, S, sp_i, sp_j)\n",
    "                sel_feats=[]\n",
    "                for n_a in range(len(block_a.features)):\n",
    "                    f_a = tuple(block_a.features[n_a]) #values of n_a'th feature in block_a.features\n",
    "                    for n_b in range(len(block_b.features)):\n",
    "                        f_b = tuple(block_b.features[n_b]) #values of n_b'th feature in block_b.features\n",
    "                        IDX = f_a  + (lam_a,)+f_b + (lam_b,)\n",
    "                        sel_feats.append([n_a, n_b])\n",
    "                        X_idx[block_idx].append(IDX)\n",
    "\n",
    "                sel_feats = np.asarray(sel_feats, dtype=int)\n",
    "                if len(sel_feats) == 0:\n",
    "                    print(IDX, L, \"len_feats 0\")\n",
    "                    continue\n",
    "\n",
    "    #             #REMEMBER- values.shape = (nstruct*nat fitting the block criteria, 2*l+1, featsize)\n",
    "                if block_type==0:\n",
    "                    if not(sp_i== rho_sp_i):\n",
    "                        continue\n",
    "                    one_shot_blocks = cg.combine_einsum(\n",
    "                     block_a.values[:, :, sel_feats[:, 0]],  #sel_feats[:,0]= n_a\n",
    "                     block_b.values[:, :, sel_feats[:, 1]],  #sel_feats[:,1]= n_b*nspecies\n",
    "                    L,\n",
    "                    combination_string=\"iq,iq->iq\",\n",
    "                ) \n",
    "\n",
    "                    samples = block_a.samples\n",
    "\n",
    "                elif block_type==1: #or block_type==-1: \n",
    "                    if not(sp_i== rho_sp_i):\n",
    "                        continue\n",
    "                    one_shot_blocks_ij = cg.combine_einsum(\n",
    "                     block_a.values[:, :, sel_feats[:, 0]], \n",
    "                     block_b.values[0::2, :, sel_feats[:, 1]],\n",
    "                    L,\n",
    "                    combination_string=\"iq,iq->iq\",\n",
    "                )\n",
    "\n",
    "                    one_shot_blocks_ji = cg.combine_einsum(\n",
    "                     block_a.values[:, :, sel_feats[:, 0]], \n",
    "                     block_b.values[1::2, :, sel_feats[:, 1]],\n",
    "                    L,\n",
    "                    combination_string=\"iq,iq->iq\",\n",
    "                )\n",
    "                    samples = block_a.samples\n",
    "                \n",
    "                    one_shot_blocks = (one_shot_blocks_ij+one_shot_blocks_ji)/np.sqrt(2)\n",
    "#                     one_shot_blocks_asym = (one_shot_blocks_ij-one_shot_blocks_ji)/np.sqrt(2)\n",
    "\n",
    "\n",
    "                elif block_type==-1:\n",
    "                    if not(sp_i== rho_sp_i):\n",
    "                        continue\n",
    "                    one_shot_blocks_ij = cg.combine_einsum(\n",
    "                     block_a.values[:, :, sel_feats[:, 0]], \n",
    "                     block_b.values[0::2, :, sel_feats[:, 1]],\n",
    "                    L,\n",
    "                    combination_string=\"iq,iq->iq\",\n",
    "                )\n",
    "\n",
    "                    one_shot_blocks_ji = cg.combine_einsum(\n",
    "                     block_a.values[:, :, sel_feats[:, 0]], \n",
    "                     block_b.values[1::2, :, sel_feats[:, 1]],\n",
    "                    L,\n",
    "                    combination_string=\"iq,iq->iq\",\n",
    "                )\n",
    "                    samples = block_a.samples\n",
    "                    one_shot_blocks = (one_shot_blocks_ij-one_shot_blocks_ji)/np.sqrt(2)\n",
    "\n",
    "                elif block_type==2:\n",
    "                    #TODO: recheck this \n",
    "    #                     if sp_i<rho_sp_i:\n",
    "    #                         continue\n",
    "                    if not(sp_i== rho_sp_i):\n",
    "                        continue\n",
    "                    #print(sp_i, rho_sp_i, sp_j, block_a.values.shape, block_b.values.shape)\n",
    "                    one_shot_blocks = cg.combine_einsum(\n",
    "                     block_a.values[:, :, sel_feats[:, 0]], \n",
    "                     block_b.values[:, :, sel_feats[:, 1]],\n",
    "                    L,\n",
    "                    combination_string=\"iq,iq->iq\",\n",
    "                )\n",
    "                    samples = block_a.samples\n",
    "\n",
    "                else: \n",
    "                    print(block_type)\n",
    "                    print(\"get the block type right you idiot\")\n",
    "\n",
    "                for Q in range(len(sel_feats)):\n",
    "                    (n_a, n_b) = sel_feats[Q]\n",
    "                    species_k, n = block_b.features[n_b]  #how to generalize this for nu\n",
    "                    IDX = (n_a,)  + (lam_a,)+(species_k,)+(n,) + (lam_b,)\n",
    "                    newblock = one_shot_blocks[:, :, Q]\n",
    "#                     if(IDX not in X_idx[(block_type, L, NU, S, sp_i, sp_j)]):\n",
    "#                         X_idx[(block_type, L, NU, S, sp_i, sp_j)].append(IDX)\n",
    "   \n",
    "                    X_blocks[block_idx].append(newblock)\n",
    "                    X_samples[block_idx].append(samples)\n",
    "    nonzero_idx = []\n",
    "\n",
    "    nonzero_blocks = []\n",
    "    for block_idx in X_blocks:\n",
    "        block_type, L, NU, S, sp_i, sp_j = block_idx\n",
    "        # create blocks\n",
    "        if len(X_blocks[block_idx]) == 0:\n",
    "            continue  # skips empty blocks\n",
    "\n",
    "        nonzero_idx.append(block_idx)\n",
    "        block_data = np.moveaxis(np.asarray(X_blocks[block_idx]), 0, -1) \n",
    "        block_samples = X_samples[block_idx][0]\n",
    "    \n",
    "        newblock = Block(\n",
    "            values=block_data,\n",
    "            samples=block_samples,\n",
    "            components=Labels(\n",
    "                [\"mu\"], np.asarray(range(-L, L + 1), dtype=np.int32).reshape(-1, 1)\n",
    "            ),\n",
    "            features=Labels(feature_names, np.asarray(X_idx[block_idx], dtype=np.int32)),\n",
    "        )\n",
    "\n",
    "        nonzero_blocks.append(newblock)\n",
    "#         print(block_idx, 'done')\n",
    "\n",
    "    X = Descriptor(\n",
    "        Labels(rho0ij.sparse.names, np.asarray(nonzero_idx, dtype=np.int32)), nonzero_blocks\n",
    "    )\n",
    "\n",
    "\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jigyasa/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:26: FutureWarning: elementwise == comparison failed and returning scalar instead; this will raise an error or perform elementwise comparison in the future.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 0, 1, 1, 1, 1) done\n",
      "(0, 1, 1, 1, 1, 1) done\n",
      "(0, 1, 1, -1, 1, 1) done\n",
      "(0, 2, 1, 1, 1, 1) done\n",
      "(0, 2, 1, -1, 1, 1) done\n",
      "(1, 0, 1, 1, 1, 1) done\n",
      "(-1, 0, 1, 1, 1, 1) done\n",
      "(1, 1, 1, 1, 1, 1) done\n",
      "(1, 1, 1, -1, 1, 1) done\n",
      "(-1, 1, 1, 1, 1, 1) done\n",
      "(-1, 1, 1, -1, 1, 1) done\n",
      "(1, 2, 1, 1, 1, 1) done\n",
      "(1, 2, 1, -1, 1, 1) done\n",
      "(-1, 2, 1, 1, 1, 1) done\n",
      "(-1, 2, 1, -1, 1, 1) done\n",
      "(2, 0, 1, 1, 1, 8) done\n",
      "(2, 1, 1, 1, 1, 8) done\n",
      "(2, 1, 1, -1, 1, 8) done\n",
      "(2, 2, 1, 1, 1, 8) done\n",
      "(2, 2, 1, -1, 1, 8) done\n",
      "(0, 0, 1, 1, 8, 8) done\n",
      "(0, 1, 1, 1, 8, 8) done\n",
      "(0, 1, 1, -1, 8, 8) done\n",
      "(0, 2, 1, 1, 8, 8) done\n",
      "(0, 2, 1, -1, 8, 8) done\n"
     ]
    }
   ],
   "source": [
    "rho1ij=tensor_g_rho_nu(rho0ij, acdc_nu1, rascal_hypers, cg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Labels([(  0, 1, 1), (  0, 2, 2), (  1, 1, 1), ..., (998, 2, 2),\n",
       "        (999, 1, 1), (999, 2, 2)],\n",
       "       dtype=[('structure', '<i4'), ('center_i', '<i4'), ('center_j', '<i4')])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rho1ij.block(0).samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TODO**: \n",
    "   - Check if the feature we get here is the same as in ncenter-reps\n",
    "   - Fix the hardcoding for water and generalize to frames with diff natoms\n",
    "   - Fix the the offd_m/offd_p computation - we are repeating calculations of block_ij, block_ji - we should reuse this (blocks_asym commented out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CRAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hamiltonian_rep(frames, hypers, nu):\n",
    "    if nu>0:\n",
    "        raise ValueError(\"nu>0 not implemented\")\n",
    "    nu0_desc = compute_rho0ij(hypers, frames)\n",
    "    \n",
    "    sparse = (block_type, center_sp, neighbor_sp, L, sigma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hypers = copy.deepcopy(self._hypers)\n",
    "if hypers[\"compute_gradients\"]:\n",
    "    raise Exception(\"Pair expansion with gradient is not implemented\")\n",
    "\n",
    "# max_atoms = max([len(f) for f in frames])\n",
    "# global_species = list(range(max_atoms))\n",
    "\n",
    "# hypers[\"global_species\"] = global_species\n",
    "# hypers[\"expansion_by_species_method\"] = \"user defined\"\n",
    "\n",
    "# ijframes = []\n",
    "# for f in frames:\n",
    "#     ijf = f.copy()\n",
    "#     ijf.numbers = global_species[:len(f)]\n",
    "#     ijframes.append(ijf)\n",
    "\n",
    "calculator = SphericalExpansion(**hypers)\n",
    "\n",
    "# Step 2: move data around to follow the storage convention\n",
    "sparse = Labels(\n",
    "    names=[\"spherical_harmonics_l\"],\n",
    "    values=np.array(\n",
    "        [\n",
    "            [l]\n",
    "            for l in range(hypers[\"max_angular\"] + 1)                    \n",
    "        ],\n",
    "        dtype=np.int32,\n",
    "    ),\n",
    ")\n",
    "\n",
    "features = Labels(\n",
    "    names=[\"n\"],\n",
    "    values=np.array([[n] for n in range(hypers[\"max_radial\"])], dtype=np.int32),\n",
    ")\n",
    "\n",
    "lm_slices = []\n",
    "start = 0\n",
    "for l in range(hypers[\"max_angular\"] + 1):\n",
    "    stop = start + 2 * l + 1\n",
    "    lm_slices.append(slice(start, stop))\n",
    "    start = stop\n",
    "\n",
    "data = []\n",
    "samples = []\n",
    "for i, ijf in enumerate(ijframes):\n",
    "    idata = calculator.transform(ijf).get_features(calculator).reshape(len(ijf), max_atoms, hypers[\"max_radial\"], -1)\n",
    "    nonzero = np.where( (idata**2).sum(axis=(2,3)) > 1e-20)\n",
    "    data.append(idata[nonzero[0], nonzero[1]].reshape(len(nonzero[0]),hypers[\"max_radial\"],-1) )\n",
    "    samples.append( np.asarray( [nonzero[0]*0+i, nonzero[0], nonzero[1]] ).T )\n",
    "\n",
    "data = np.concatenate(data)\n",
    "samples = Labels(\n",
    "        names=[\"structure\", \"center_i\", \"center_j\"],\n",
    "        values=np.concatenate(samples).astype(np.int32)\n",
    ")\n",
    "blocks = []\n",
    "for (l,) in sparse:\n",
    "    block_data = data[..., lm_slices[l]]\n",
    "    block_data = block_data.swapaxes(1, 2)\n",
    "\n",
    "    components = Labels(\n",
    "        names=[\"spherical_harmonics_m\"],\n",
    "        values=np.array([[m] for m in range(-l, l + 1)], dtype=np.int32),\n",
    "    )\n",
    "\n",
    "    block = Block(\n",
    "        values=np.copy(block_data),\n",
    "        samples=samples,\n",
    "        components=components,\n",
    "        features=features,\n",
    "    )\n",
    "\n",
    "    blocks.append(block)\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e5b9818494c5e2e4b1f356a8c3298778da7fbcf7ee16e565b1a5192ca7e31aaa"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
